I0318 11:16:30.631778  2293 caffe.cpp:217] Using GPUs 0
I0318 11:16:30.669106  2293 caffe.cpp:222] GPU 0: GeForce GTX TITAN X
I0318 11:16:30.988739  2293 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 5000
base_lr: 0.01
display: 1000
max_iter: 100000
lr_policy: "step"
gamma: 0.5
momentum: 0.75
weight_decay: 0.0002
stepsize: 20000
snapshot: 100000
snapshot_prefix: "mnist"
solver_mode: GPU
device_id: 0
net: "train_val_stats_2.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: true
average_loss: 40
I0318 11:16:30.988854  2293 solver.cpp:91] Creating training net from net file: train_val_stats_2.prototxt
I0318 11:16:30.989195  2293 net.cpp:338] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0318 11:16:30.989213  2293 net.cpp:338] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0318 11:16:30.989326  2293 net.cpp:74] Initializing net from parameters: 
name: "MNIST_NET"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  image_data_param {
    source: "train.txt"
    batch_size: 300
    crop_size: 27
    shuffle: true
    is_color: false
  }
}
layer {
  name: "data_scaling"
  type: "Power"
  bottom: "data"
  top: "data"
  power_param {
    power: 1
    scale: 0.0078125
    shift: -1
  }
}
layer {
  name: "data_drop"
  type: "Dropout"
  bottom: "data"
  top: "data"
  include {
    phase: TRAIN
  }
  dropout_param {
    dropout_ratio: 0.01
  }
}
layer {
  name: "data_vision"
  type: "VisionTransformation"
  bottom: "data"
  top: "data"
  include {
    phase: TRAIN
  }
  vision_transformation_param {
    noise_mean: 0
    noise_std: 0
    noise_std_small: 0
    rotate_min_angle: -20
    rotate_max_angle: 20
    rotate_fill_value: 0
    per_pixel_multiplier_mean: 1
    per_pixel_multiplier_std: 0
    rescale_probability: 0.25
    constant_multiplier_mean: 1
    constant_multiplier_std: 0
    scale_mean: 1
    scale_std: 0.1
    constant_multiplier_color_mean: 0
    constant_multiplier_color_std: 0
    value_cap_min: 0
    value_cap_max: 0
    passthrough_probability: 0.5
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1_pos"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_pos"
  top: "conv2"
  param {
    name: "conv2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "block_output"
  type: "Concat"
  bottom: "conv2"
  top: "block_output"
}
layer {
  name: "block_output_prelu"
  type: "PReLU"
  bottom: "block_output"
  top: "block_output"
  prelu_param {
    filler {
      type: "constant"
      value: 0.01
    }
  }
}
layer {
  name: "fc_10"
  type: "InnerProduct"
  bottom: "block_output"
  top: "fc_10"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc_10"
  bottom: "label"
  top: "loss"
  include {
    phase: TRAIN
  }
}
I0318 11:16:30.989388  2293 layer_factory.hpp:77] Creating layer data
I0318 11:16:30.989418  2293 net.cpp:116] Creating Layer data
I0318 11:16:30.989423  2293 net.cpp:424] data -> data
I0318 11:16:30.989440  2293 net.cpp:424] data -> label
I0318 11:16:30.989451  2293 image_data_layer.cpp:38] Opening file train.txt
I0318 11:16:31.001760  2293 image_data_layer.cpp:53] Shuffling data
I0318 11:16:31.005878  2293 image_data_layer.cpp:58] A total of 60000 images.
I0318 11:16:31.016196  2293 image_data_layer.cpp:85] output data size: 300,1,28,28
I0318 11:16:31.018786  2293 net.cpp:166] Setting up data
I0318 11:16:31.018805  2293 net.cpp:173] Top shape: 300 1 28 28 (235200)
I0318 11:16:31.018810  2293 net.cpp:173] Top shape: 300 (300)
I0318 11:16:31.018811  2293 net.cpp:181] Memory required for data: 942000
I0318 11:16:31.018820  2293 layer_factory.hpp:77] Creating layer data_scaling
I0318 11:16:31.018837  2293 net.cpp:116] Creating Layer data_scaling
I0318 11:16:31.018841  2293 net.cpp:450] data_scaling <- data
I0318 11:16:31.018851  2293 net.cpp:411] data_scaling -> data (in-place)
I0318 11:16:31.018862  2293 net.cpp:166] Setting up data_scaling
I0318 11:16:31.018864  2293 net.cpp:173] Top shape: 300 1 28 28 (235200)
I0318 11:16:31.018867  2293 net.cpp:181] Memory required for data: 1882800
I0318 11:16:31.018869  2293 layer_factory.hpp:77] Creating layer data_drop
I0318 11:16:31.018875  2293 net.cpp:116] Creating Layer data_drop
I0318 11:16:31.018878  2293 net.cpp:450] data_drop <- data
I0318 11:16:31.018882  2293 net.cpp:411] data_drop -> data (in-place)
I0318 11:16:31.018929  2293 net.cpp:166] Setting up data_drop
I0318 11:16:31.018934  2293 net.cpp:173] Top shape: 300 1 28 28 (235200)
I0318 11:16:31.018936  2293 net.cpp:181] Memory required for data: 2823600
I0318 11:16:31.018939  2293 layer_factory.hpp:77] Creating layer data_vision
I0318 11:16:31.018944  2293 net.cpp:116] Creating Layer data_vision
I0318 11:16:31.018947  2293 net.cpp:450] data_vision <- data
I0318 11:16:31.018950  2293 net.cpp:411] data_vision -> data (in-place)
I0318 11:16:31.018963  2293 net.cpp:166] Setting up data_vision
I0318 11:16:31.018967  2293 net.cpp:173] Top shape: 300 1 28 28 (235200)
I0318 11:16:31.018970  2293 net.cpp:181] Memory required for data: 3764400
I0318 11:16:31.018971  2293 layer_factory.hpp:77] Creating layer conv1
I0318 11:16:31.018985  2293 net.cpp:116] Creating Layer conv1
I0318 11:16:31.018986  2293 net.cpp:450] conv1 <- data
I0318 11:16:31.018990  2293 net.cpp:424] conv1 -> conv1
I0318 11:16:31.191041  2293 net.cpp:166] Setting up conv1
I0318 11:16:31.191067  2293 net.cpp:173] Top shape: 300 36 13 13 (1825200)
I0318 11:16:31.191071  2293 net.cpp:181] Memory required for data: 11065200
I0318 11:16:31.191085  2293 layer_factory.hpp:77] Creating layer relu1
I0318 11:16:31.191095  2293 net.cpp:116] Creating Layer relu1
I0318 11:16:31.191099  2293 net.cpp:450] relu1 <- conv1
I0318 11:16:31.191104  2293 net.cpp:424] relu1 -> conv1_pos
I0318 11:16:31.191401  2293 net.cpp:166] Setting up relu1
I0318 11:16:31.191412  2293 net.cpp:173] Top shape: 300 36 13 13 (1825200)
I0318 11:16:31.191414  2293 net.cpp:181] Memory required for data: 18366000
I0318 11:16:31.191417  2293 layer_factory.hpp:77] Creating layer conv2
I0318 11:16:31.191428  2293 net.cpp:116] Creating Layer conv2
I0318 11:16:31.191431  2293 net.cpp:450] conv2 <- conv1_pos
I0318 11:16:31.191437  2293 net.cpp:424] conv2 -> conv2
I0318 11:16:31.193002  2293 net.cpp:166] Setting up conv2
I0318 11:16:31.193015  2293 net.cpp:173] Top shape: 300 128 6 6 (1382400)
I0318 11:16:31.193018  2293 net.cpp:181] Memory required for data: 23895600
I0318 11:16:31.193025  2293 layer_factory.hpp:77] Creating layer block_output
I0318 11:16:31.193032  2293 net.cpp:116] Creating Layer block_output
I0318 11:16:31.193035  2293 net.cpp:450] block_output <- conv2
I0318 11:16:31.193038  2293 net.cpp:424] block_output -> block_output
I0318 11:16:31.193066  2293 net.cpp:166] Setting up block_output
I0318 11:16:31.193075  2293 net.cpp:173] Top shape: 300 128 6 6 (1382400)
I0318 11:16:31.193078  2293 net.cpp:181] Memory required for data: 29425200
I0318 11:16:31.193079  2293 layer_factory.hpp:77] Creating layer block_output_prelu
I0318 11:16:31.193087  2293 net.cpp:116] Creating Layer block_output_prelu
I0318 11:16:31.193090  2293 net.cpp:450] block_output_prelu <- block_output
I0318 11:16:31.193095  2293 net.cpp:411] block_output_prelu -> block_output (in-place)
I0318 11:16:31.193532  2293 net.cpp:166] Setting up block_output_prelu
I0318 11:16:31.193557  2293 net.cpp:173] Top shape: 300 128 6 6 (1382400)
I0318 11:16:31.193559  2293 net.cpp:181] Memory required for data: 34954800
I0318 11:16:31.193567  2293 layer_factory.hpp:77] Creating layer fc_10
I0318 11:16:31.193574  2293 net.cpp:116] Creating Layer fc_10
I0318 11:16:31.193577  2293 net.cpp:450] fc_10 <- block_output
I0318 11:16:31.193581  2293 net.cpp:424] fc_10 -> fc_10
I0318 11:16:31.194715  2293 net.cpp:166] Setting up fc_10
I0318 11:16:31.194723  2293 net.cpp:173] Top shape: 300 10 (3000)
I0318 11:16:31.194725  2293 net.cpp:181] Memory required for data: 34966800
I0318 11:16:31.194730  2293 layer_factory.hpp:77] Creating layer loss
I0318 11:16:31.194737  2293 net.cpp:116] Creating Layer loss
I0318 11:16:31.194741  2293 net.cpp:450] loss <- fc_10
I0318 11:16:31.194743  2293 net.cpp:450] loss <- label
I0318 11:16:31.194747  2293 net.cpp:424] loss -> loss
I0318 11:16:31.194756  2293 layer_factory.hpp:77] Creating layer loss
I0318 11:16:31.195363  2293 net.cpp:166] Setting up loss
I0318 11:16:31.195376  2293 net.cpp:173] Top shape: (1)
I0318 11:16:31.195379  2293 net.cpp:176]     with loss weight 1
I0318 11:16:31.195394  2293 net.cpp:181] Memory required for data: 34966804
I0318 11:16:31.195396  2293 net.cpp:242] loss needs backward computation.
I0318 11:16:31.195399  2293 net.cpp:242] fc_10 needs backward computation.
I0318 11:16:31.195401  2293 net.cpp:242] block_output_prelu needs backward computation.
I0318 11:16:31.195403  2293 net.cpp:242] block_output needs backward computation.
I0318 11:16:31.195405  2293 net.cpp:242] conv2 needs backward computation.
I0318 11:16:31.195407  2293 net.cpp:242] relu1 needs backward computation.
I0318 11:16:31.195410  2293 net.cpp:242] conv1 needs backward computation.
I0318 11:16:31.195412  2293 net.cpp:244] data_vision does not need backward computation.
I0318 11:16:31.195415  2293 net.cpp:244] data_drop does not need backward computation.
I0318 11:16:31.195416  2293 net.cpp:244] data_scaling does not need backward computation.
I0318 11:16:31.195420  2293 net.cpp:244] data does not need backward computation.
I0318 11:16:31.195421  2293 net.cpp:286] This network produces output loss
I0318 11:16:31.195428  2293 net.cpp:299] Network initialization done.
I0318 11:16:31.195725  2293 solver.cpp:181] Creating test net (#0) specified by net file: train_val_stats_2.prototxt
I0318 11:16:31.195751  2293 net.cpp:338] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0318 11:16:31.195758  2293 net.cpp:338] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_drop
I0318 11:16:31.195760  2293 net.cpp:338] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_vision
I0318 11:16:31.195765  2293 net.cpp:338] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss
I0318 11:16:31.195857  2293 net.cpp:74] Initializing net from parameters: 
name: "MNIST_NET"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  image_data_param {
    source: "test.txt"
    batch_size: 100
    crop_size: 27
    shuffle: true
    is_color: false
  }
}
layer {
  name: "data_scaling"
  type: "Power"
  bottom: "data"
  top: "data"
  power_param {
    power: 1
    scale: 0.0078125
    shift: -1
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1_pos"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1_pos"
  top: "conv2"
  param {
    name: "conv2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "block_output"
  type: "Concat"
  bottom: "conv2"
  top: "block_output"
}
layer {
  name: "block_output_prelu"
  type: "PReLU"
  bottom: "block_output"
  top: "block_output"
  prelu_param {
    filler {
      type: "constant"
      value: 0.01
    }
  }
}
layer {
  name: "fc_10"
  type: "InnerProduct"
  bottom: "block_output"
  top: "fc_10"
  param {
    lr_mult: 5
    decay_mult: 1
  }
  param {
    lr_mult: 10
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc_10"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0318 11:16:31.195906  2293 layer_factory.hpp:77] Creating layer data
I0318 11:16:31.195917  2293 net.cpp:116] Creating Layer data
I0318 11:16:31.195922  2293 net.cpp:424] data -> data
I0318 11:16:31.195929  2293 net.cpp:424] data -> label
I0318 11:16:31.195935  2293 image_data_layer.cpp:38] Opening file test.txt
I0318 11:16:31.198236  2293 image_data_layer.cpp:53] Shuffling data
I0318 11:16:31.198810  2293 image_data_layer.cpp:58] A total of 10000 images.
I0318 11:16:31.198935  2293 image_data_layer.cpp:85] output data size: 100,1,28,28
I0318 11:16:31.199780  2293 net.cpp:166] Setting up data
I0318 11:16:31.199792  2293 net.cpp:173] Top shape: 100 1 28 28 (78400)
I0318 11:16:31.199796  2293 net.cpp:173] Top shape: 100 (100)
I0318 11:16:31.199798  2293 net.cpp:181] Memory required for data: 314000
I0318 11:16:31.199801  2293 layer_factory.hpp:77] Creating layer data_scaling
I0318 11:16:31.199807  2293 net.cpp:116] Creating Layer data_scaling
I0318 11:16:31.199810  2293 net.cpp:450] data_scaling <- data
I0318 11:16:31.199815  2293 net.cpp:411] data_scaling -> data (in-place)
I0318 11:16:31.199820  2293 net.cpp:166] Setting up data_scaling
I0318 11:16:31.199823  2293 net.cpp:173] Top shape: 100 1 28 28 (78400)
I0318 11:16:31.199826  2293 net.cpp:181] Memory required for data: 627600
I0318 11:16:31.199827  2293 layer_factory.hpp:77] Creating layer conv1
I0318 11:16:31.199834  2293 net.cpp:116] Creating Layer conv1
I0318 11:16:31.199836  2293 net.cpp:450] conv1 <- data
I0318 11:16:31.199839  2293 net.cpp:424] conv1 -> conv1
I0318 11:16:31.201061  2293 net.cpp:166] Setting up conv1
I0318 11:16:31.201074  2293 net.cpp:173] Top shape: 100 36 13 13 (608400)
I0318 11:16:31.201076  2293 net.cpp:181] Memory required for data: 3061200
I0318 11:16:31.201084  2293 layer_factory.hpp:77] Creating layer relu1
I0318 11:16:31.201089  2293 net.cpp:116] Creating Layer relu1
I0318 11:16:31.201092  2293 net.cpp:450] relu1 <- conv1
I0318 11:16:31.201097  2293 net.cpp:424] relu1 -> conv1_pos
I0318 11:16:31.201395  2293 net.cpp:166] Setting up relu1
I0318 11:16:31.201406  2293 net.cpp:173] Top shape: 100 36 13 13 (608400)
I0318 11:16:31.201408  2293 net.cpp:181] Memory required for data: 5494800
I0318 11:16:31.201411  2293 layer_factory.hpp:77] Creating layer conv2
I0318 11:16:31.201421  2293 net.cpp:116] Creating Layer conv2
I0318 11:16:31.201423  2293 net.cpp:450] conv2 <- conv1_pos
I0318 11:16:31.201429  2293 net.cpp:424] conv2 -> conv2
I0318 11:16:31.202502  2293 net.cpp:166] Setting up conv2
I0318 11:16:31.202515  2293 net.cpp:173] Top shape: 100 128 6 6 (460800)
I0318 11:16:31.202517  2293 net.cpp:181] Memory required for data: 7338000
I0318 11:16:31.202525  2293 layer_factory.hpp:77] Creating layer block_output
I0318 11:16:31.202530  2293 net.cpp:116] Creating Layer block_output
I0318 11:16:31.202533  2293 net.cpp:450] block_output <- conv2
I0318 11:16:31.202538  2293 net.cpp:424] block_output -> block_output
I0318 11:16:31.202565  2293 net.cpp:166] Setting up block_output
I0318 11:16:31.202570  2293 net.cpp:173] Top shape: 100 128 6 6 (460800)
I0318 11:16:31.202572  2293 net.cpp:181] Memory required for data: 9181200
I0318 11:16:31.202574  2293 layer_factory.hpp:77] Creating layer block_output_prelu
I0318 11:16:31.202579  2293 net.cpp:116] Creating Layer block_output_prelu
I0318 11:16:31.202591  2293 net.cpp:450] block_output_prelu <- block_output
I0318 11:16:31.202596  2293 net.cpp:411] block_output_prelu -> block_output (in-place)
I0318 11:16:31.202671  2293 net.cpp:166] Setting up block_output_prelu
I0318 11:16:31.202674  2293 net.cpp:173] Top shape: 100 128 6 6 (460800)
I0318 11:16:31.202677  2293 net.cpp:181] Memory required for data: 11024400
I0318 11:16:31.202682  2293 layer_factory.hpp:77] Creating layer fc_10
I0318 11:16:31.202687  2293 net.cpp:116] Creating Layer fc_10
I0318 11:16:31.202690  2293 net.cpp:450] fc_10 <- block_output
I0318 11:16:31.202694  2293 net.cpp:424] fc_10 -> fc_10
I0318 11:16:31.203840  2293 net.cpp:166] Setting up fc_10
I0318 11:16:31.203848  2293 net.cpp:173] Top shape: 100 10 (1000)
I0318 11:16:31.203851  2293 net.cpp:181] Memory required for data: 11028400
I0318 11:16:31.203855  2293 layer_factory.hpp:77] Creating layer accuracy
I0318 11:16:31.203863  2293 net.cpp:116] Creating Layer accuracy
I0318 11:16:31.203866  2293 net.cpp:450] accuracy <- fc_10
I0318 11:16:31.203869  2293 net.cpp:450] accuracy <- label
I0318 11:16:31.203873  2293 net.cpp:424] accuracy -> accuracy
I0318 11:16:31.203881  2293 net.cpp:166] Setting up accuracy
I0318 11:16:31.203883  2293 net.cpp:173] Top shape: (1)
I0318 11:16:31.203886  2293 net.cpp:181] Memory required for data: 11028404
I0318 11:16:31.203888  2293 net.cpp:244] accuracy does not need backward computation.
I0318 11:16:31.203891  2293 net.cpp:244] fc_10 does not need backward computation.
I0318 11:16:31.203893  2293 net.cpp:244] block_output_prelu does not need backward computation.
I0318 11:16:31.203896  2293 net.cpp:244] block_output does not need backward computation.
I0318 11:16:31.203897  2293 net.cpp:244] conv2 does not need backward computation.
I0318 11:16:31.203899  2293 net.cpp:244] relu1 does not need backward computation.
I0318 11:16:31.203902  2293 net.cpp:244] conv1 does not need backward computation.
I0318 11:16:31.203904  2293 net.cpp:244] data_scaling does not need backward computation.
I0318 11:16:31.203907  2293 net.cpp:244] data does not need backward computation.
I0318 11:16:31.203908  2293 net.cpp:286] This network produces output accuracy
I0318 11:16:31.203914  2293 net.cpp:299] Network initialization done.
I0318 11:16:31.203943  2293 solver.cpp:60] Solver scaffolding done.
I0318 11:16:31.204149  2293 caffe.cpp:251] Starting Optimization
I0318 11:16:31.204156  2293 solver.cpp:279] Solving MNIST_NET
I0318 11:16:31.204159  2293 solver.cpp:280] Learning Rate Policy: step
I0318 11:16:31.204464  2293 solver.cpp:337] Iteration 0, Testing net (#0)
I0318 11:16:31.204475  2293 net.cpp:709] Ignoring source layer data_drop
I0318 11:16:31.204478  2293 net.cpp:709] Ignoring source layer data_vision
I0318 11:16:31.204548  2293 net.cpp:709] Ignoring source layer loss
I0318 11:16:31.204557  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:16:31.483054  2293 solver.cpp:404]     Test net output #0: accuracy = 0.0913
I0318 11:16:31.504986  2293 solver.cpp:228] Iteration 0, loss = 2.35437
I0318 11:16:31.505020  2293 solver.cpp:244]     Train net output #0: loss = 2.35437 (* 1 = 2.35437 loss)
I0318 11:16:31.505034  2293 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0318 11:16:38.685232  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:16:39.442987  2293 solver.cpp:228] Iteration 1000, loss = 0.100613
I0318 11:16:39.443024  2293 solver.cpp:244]     Train net output #0: loss = 0.0557195 (* 1 = 0.0557195 loss)
I0318 11:16:39.443030  2293 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I0318 11:16:46.459003  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:16:47.215881  2293 solver.cpp:228] Iteration 2000, loss = 0.0819286
I0318 11:16:47.215916  2293 solver.cpp:244]     Train net output #0: loss = 0.0637428 (* 1 = 0.0637428 loss)
I0318 11:16:47.215922  2293 sgd_solver.cpp:106] Iteration 2000, lr = 0.01
I0318 11:16:54.227849  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:16:54.985050  2293 solver.cpp:228] Iteration 3000, loss = 0.0731677
I0318 11:16:54.985079  2293 solver.cpp:244]     Train net output #0: loss = 0.0934931 (* 1 = 0.0934931 loss)
I0318 11:16:54.985103  2293 sgd_solver.cpp:106] Iteration 3000, lr = 0.01
I0318 11:17:02.025632  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:17:02.782019  2293 solver.cpp:228] Iteration 4000, loss = 0.056816
I0318 11:17:02.782100  2293 solver.cpp:244]     Train net output #0: loss = 0.0592045 (* 1 = 0.0592045 loss)
I0318 11:17:02.782122  2293 sgd_solver.cpp:106] Iteration 4000, lr = 0.01
I0318 11:17:09.795454  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:17:10.544415  2293 solver.cpp:337] Iteration 5000, Testing net (#0)
I0318 11:17:10.544435  2293 net.cpp:709] Ignoring source layer data_drop
I0318 11:17:10.544440  2293 net.cpp:709] Ignoring source layer data_vision
I0318 11:17:10.544445  2293 net.cpp:709] Ignoring source layer loss
I0318 11:17:10.762822  2293 solver.cpp:404]     Test net output #0: accuracy = 0.9868
I0318 11:17:10.766551  2293 solver.cpp:228] Iteration 5000, loss = 0.0614971
I0318 11:17:10.766577  2293 solver.cpp:244]     Train net output #0: loss = 0.0448266 (* 1 = 0.0448266 loss)
I0318 11:17:10.766583  2293 sgd_solver.cpp:106] Iteration 5000, lr = 0.01
I0318 11:17:17.060736  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:17:18.528249  2293 solver.cpp:228] Iteration 6000, loss = 0.0603305
I0318 11:17:18.528447  2293 solver.cpp:244]     Train net output #0: loss = 0.0438774 (* 1 = 0.0438774 loss)
I0318 11:17:18.528456  2293 sgd_solver.cpp:106] Iteration 6000, lr = 0.01
I0318 11:17:24.828742  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:17:26.298390  2293 solver.cpp:228] Iteration 7000, loss = 0.0482594
I0318 11:17:26.298470  2293 solver.cpp:244]     Train net output #0: loss = 0.0402701 (* 1 = 0.0402701 loss)
I0318 11:17:26.298491  2293 sgd_solver.cpp:106] Iteration 7000, lr = 0.01
I0318 11:17:32.604490  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:17:34.075449  2293 solver.cpp:228] Iteration 8000, loss = 0.045309
I0318 11:17:34.075479  2293 solver.cpp:244]     Train net output #0: loss = 0.0427038 (* 1 = 0.0427038 loss)
I0318 11:17:34.075484  2293 sgd_solver.cpp:106] Iteration 8000, lr = 0.01
I0318 11:17:40.378624  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:17:41.851407  2293 solver.cpp:228] Iteration 9000, loss = 0.0473881
I0318 11:17:41.851485  2293 solver.cpp:244]     Train net output #0: loss = 0.026187 (* 1 = 0.026187 loss)
I0318 11:17:41.851507  2293 sgd_solver.cpp:106] Iteration 9000, lr = 0.01
I0318 11:17:48.157145  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:17:49.615295  2293 solver.cpp:337] Iteration 10000, Testing net (#0)
I0318 11:17:49.615315  2293 net.cpp:709] Ignoring source layer data_drop
I0318 11:17:49.615319  2293 net.cpp:709] Ignoring source layer data_vision
I0318 11:17:49.615325  2293 net.cpp:709] Ignoring source layer loss
I0318 11:17:49.863564  2293 solver.cpp:404]     Test net output #0: accuracy = 0.9896
I0318 11:17:49.867595  2293 solver.cpp:228] Iteration 10000, loss = 0.0454156
I0318 11:17:49.867637  2293 solver.cpp:244]     Train net output #0: loss = 0.0276499 (* 1 = 0.0276499 loss)
I0318 11:17:49.867650  2293 sgd_solver.cpp:106] Iteration 10000, lr = 0.01
I0318 11:17:55.442211  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:17:57.630944  2293 solver.cpp:228] Iteration 11000, loss = 0.0425225
I0318 11:17:57.631026  2293 solver.cpp:244]     Train net output #0: loss = 0.0241444 (* 1 = 0.0241444 loss)
I0318 11:17:57.631047  2293 sgd_solver.cpp:106] Iteration 11000, lr = 0.01
I0318 11:18:03.222812  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:18:05.407105  2293 solver.cpp:228] Iteration 12000, loss = 0.0357995
I0318 11:18:05.407183  2293 solver.cpp:244]     Train net output #0: loss = 0.0341632 (* 1 = 0.0341632 loss)
I0318 11:18:05.407205  2293 sgd_solver.cpp:106] Iteration 12000, lr = 0.01
I0318 11:18:10.987947  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:18:13.174388  2293 solver.cpp:228] Iteration 13000, loss = 0.0377069
I0318 11:18:13.174424  2293 solver.cpp:244]     Train net output #0: loss = 0.0394483 (* 1 = 0.0394483 loss)
I0318 11:18:13.174430  2293 sgd_solver.cpp:106] Iteration 13000, lr = 0.01
I0318 11:18:18.744592  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:18:20.929219  2293 solver.cpp:228] Iteration 14000, loss = 0.0407902
I0318 11:18:20.929419  2293 solver.cpp:244]     Train net output #0: loss = 0.0118378 (* 1 = 0.0118378 loss)
I0318 11:18:20.929428  2293 sgd_solver.cpp:106] Iteration 14000, lr = 0.01
I0318 11:18:26.507074  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:18:28.668918  2293 solver.cpp:337] Iteration 15000, Testing net (#0)
I0318 11:18:28.668941  2293 net.cpp:709] Ignoring source layer data_drop
I0318 11:18:28.668943  2293 net.cpp:709] Ignoring source layer data_vision
I0318 11:18:28.668949  2293 net.cpp:709] Ignoring source layer loss
I0318 11:18:28.900957  2293 solver.cpp:404]     Test net output #0: accuracy = 0.9909
I0318 11:18:28.904825  2293 solver.cpp:228] Iteration 15000, loss = 0.0368634
I0318 11:18:28.904870  2293 solver.cpp:244]     Train net output #0: loss = 0.0129095 (* 1 = 0.0129095 loss)
I0318 11:18:28.904886  2293 sgd_solver.cpp:106] Iteration 15000, lr = 0.01
I0318 11:18:33.783093  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:18:36.674305  2293 solver.cpp:228] Iteration 16000, loss = 0.036524
I0318 11:18:36.674384  2293 solver.cpp:244]     Train net output #0: loss = 0.0493648 (* 1 = 0.0493648 loss)
I0318 11:18:36.674409  2293 sgd_solver.cpp:106] Iteration 16000, lr = 0.01
I0318 11:18:41.552476  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:18:44.442818  2293 solver.cpp:228] Iteration 17000, loss = 0.0319072
I0318 11:18:44.442898  2293 solver.cpp:244]     Train net output #0: loss = 0.0308052 (* 1 = 0.0308052 loss)
I0318 11:18:44.442919  2293 sgd_solver.cpp:106] Iteration 17000, lr = 0.01
I0318 11:18:49.311964  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:18:52.203603  2293 solver.cpp:228] Iteration 18000, loss = 0.0344827
I0318 11:18:52.203682  2293 solver.cpp:244]     Train net output #0: loss = 0.0550445 (* 1 = 0.0550445 loss)
I0318 11:18:52.203703  2293 sgd_solver.cpp:106] Iteration 18000, lr = 0.01
I0318 11:18:57.075631  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:18:59.965556  2293 solver.cpp:228] Iteration 19000, loss = 0.0368752
I0318 11:18:59.965639  2293 solver.cpp:244]     Train net output #0: loss = 0.0355532 (* 1 = 0.0355532 loss)
I0318 11:18:59.965661  2293 sgd_solver.cpp:106] Iteration 19000, lr = 0.01
I0318 11:19:04.844522  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:19:07.726114  2293 solver.cpp:337] Iteration 20000, Testing net (#0)
I0318 11:19:07.726179  2293 net.cpp:709] Ignoring source layer data_drop
I0318 11:19:07.726186  2293 net.cpp:709] Ignoring source layer data_vision
I0318 11:19:07.726189  2293 net.cpp:709] Ignoring source layer loss
I0318 11:19:07.943758  2293 solver.cpp:404]     Test net output #0: accuracy = 0.9915
I0318 11:19:07.947376  2293 solver.cpp:228] Iteration 20000, loss = 0.0308984
I0318 11:19:07.947433  2293 solver.cpp:244]     Train net output #0: loss = 0.00763136 (* 1 = 0.00763136 loss)
I0318 11:19:07.947477  2293 sgd_solver.cpp:106] Iteration 20000, lr = 0.005
I0318 11:19:12.108511  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:19:15.704702  2293 solver.cpp:228] Iteration 21000, loss = 0.0302204
I0318 11:19:15.704784  2293 solver.cpp:244]     Train net output #0: loss = 0.0371938 (* 1 = 0.0371938 loss)
I0318 11:19:15.704807  2293 sgd_solver.cpp:106] Iteration 21000, lr = 0.005
I0318 11:19:19.871676  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:19:23.472589  2293 solver.cpp:228] Iteration 22000, loss = 0.0277351
I0318 11:19:23.472868  2293 solver.cpp:244]     Train net output #0: loss = 0.013176 (* 1 = 0.013176 loss)
I0318 11:19:23.472877  2293 sgd_solver.cpp:106] Iteration 22000, lr = 0.005
I0318 11:19:27.642307  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:19:31.242238  2293 solver.cpp:228] Iteration 23000, loss = 0.0263022
I0318 11:19:31.242446  2293 solver.cpp:244]     Train net output #0: loss = 0.0105464 (* 1 = 0.0105464 loss)
I0318 11:19:31.242456  2293 sgd_solver.cpp:106] Iteration 23000, lr = 0.005
I0318 11:19:35.408421  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:19:39.005879  2293 solver.cpp:228] Iteration 24000, loss = 0.0278206
I0318 11:19:39.005957  2293 solver.cpp:244]     Train net output #0: loss = 0.0669973 (* 1 = 0.0669973 loss)
I0318 11:19:39.005980  2293 sgd_solver.cpp:106] Iteration 24000, lr = 0.005
I0318 11:19:43.177605  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:19:46.766064  2293 solver.cpp:337] Iteration 25000, Testing net (#0)
I0318 11:19:46.766129  2293 net.cpp:709] Ignoring source layer data_drop
I0318 11:19:46.766136  2293 net.cpp:709] Ignoring source layer data_vision
I0318 11:19:46.766142  2293 net.cpp:709] Ignoring source layer loss
I0318 11:19:46.984191  2293 solver.cpp:404]     Test net output #0: accuracy = 0.9916
I0318 11:19:46.988162  2293 solver.cpp:228] Iteration 25000, loss = 0.0275888
I0318 11:19:46.988425  2293 solver.cpp:244]     Train net output #0: loss = 0.0249556 (* 1 = 0.0249556 loss)
I0318 11:19:46.988644  2293 sgd_solver.cpp:106] Iteration 25000, lr = 0.005
I0318 11:19:50.453380  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:19:54.754561  2293 solver.cpp:228] Iteration 26000, loss = 0.0291603
I0318 11:19:54.754772  2293 solver.cpp:244]     Train net output #0: loss = 0.0139345 (* 1 = 0.0139345 loss)
I0318 11:19:54.754783  2293 sgd_solver.cpp:106] Iteration 26000, lr = 0.005
I0318 11:19:58.215234  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:20:02.523177  2293 solver.cpp:228] Iteration 27000, loss = 0.026446
I0318 11:20:02.523259  2293 solver.cpp:244]     Train net output #0: loss = 0.0163965 (* 1 = 0.0163965 loss)
I0318 11:20:02.523280  2293 sgd_solver.cpp:106] Iteration 27000, lr = 0.005
I0318 11:20:05.988488  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:20:10.291690  2293 solver.cpp:228] Iteration 28000, loss = 0.0238764
I0318 11:20:10.291769  2293 solver.cpp:244]     Train net output #0: loss = 0.0169145 (* 1 = 0.0169145 loss)
I0318 11:20:10.291792  2293 sgd_solver.cpp:106] Iteration 28000, lr = 0.005
I0318 11:20:13.756153  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:20:18.055894  2293 solver.cpp:228] Iteration 29000, loss = 0.0270747
I0318 11:20:18.055974  2293 solver.cpp:244]     Train net output #0: loss = 0.0123875 (* 1 = 0.0123875 loss)
I0318 11:20:18.055996  2293 sgd_solver.cpp:106] Iteration 29000, lr = 0.005
I0318 11:20:21.514343  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:20:25.804180  2293 solver.cpp:337] Iteration 30000, Testing net (#0)
I0318 11:20:25.804198  2293 net.cpp:709] Ignoring source layer data_drop
I0318 11:20:25.804200  2293 net.cpp:709] Ignoring source layer data_vision
I0318 11:20:25.804203  2293 net.cpp:709] Ignoring source layer loss
I0318 11:20:26.022531  2293 solver.cpp:404]     Test net output #0: accuracy = 0.9917
I0318 11:20:26.026262  2293 solver.cpp:228] Iteration 30000, loss = 0.0310892
I0318 11:20:26.026314  2293 solver.cpp:244]     Train net output #0: loss = 0.0261482 (* 1 = 0.0261482 loss)
I0318 11:20:26.026337  2293 sgd_solver.cpp:106] Iteration 30000, lr = 0.005
I0318 11:20:28.782840  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:20:33.817605  2293 solver.cpp:228] Iteration 31000, loss = 0.0284444
I0318 11:20:33.817695  2293 solver.cpp:244]     Train net output #0: loss = 0.0137259 (* 1 = 0.0137259 loss)
I0318 11:20:33.817718  2293 sgd_solver.cpp:106] Iteration 31000, lr = 0.005
I0318 11:20:36.546607  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:20:41.574537  2293 solver.cpp:228] Iteration 32000, loss = 0.0291137
I0318 11:20:41.574636  2293 solver.cpp:244]     Train net output #0: loss = 0.0254072 (* 1 = 0.0254072 loss)
I0318 11:20:41.574658  2293 sgd_solver.cpp:106] Iteration 32000, lr = 0.005
I0318 11:20:44.306797  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:20:49.341616  2293 solver.cpp:228] Iteration 33000, loss = 0.026106
I0318 11:20:49.341697  2293 solver.cpp:244]     Train net output #0: loss = 0.0163462 (* 1 = 0.0163462 loss)
I0318 11:20:49.341719  2293 sgd_solver.cpp:106] Iteration 33000, lr = 0.005
I0318 11:20:52.068292  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:20:57.100441  2293 solver.cpp:228] Iteration 34000, loss = 0.0264723
I0318 11:20:57.100522  2293 solver.cpp:244]     Train net output #0: loss = 0.0165079 (* 1 = 0.0165079 loss)
I0318 11:20:57.100546  2293 sgd_solver.cpp:106] Iteration 34000, lr = 0.005
I0318 11:20:59.830113  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:21:04.854149  2293 solver.cpp:337] Iteration 35000, Testing net (#0)
I0318 11:21:04.854221  2293 net.cpp:709] Ignoring source layer data_drop
I0318 11:21:04.854228  2293 net.cpp:709] Ignoring source layer data_vision
I0318 11:21:04.854234  2293 net.cpp:709] Ignoring source layer loss
I0318 11:21:05.071003  2293 solver.cpp:404]     Test net output #0: accuracy = 0.9913
I0318 11:21:05.074841  2293 solver.cpp:228] Iteration 35000, loss = 0.0282775
I0318 11:21:05.074864  2293 solver.cpp:244]     Train net output #0: loss = 0.0250269 (* 1 = 0.0250269 loss)
I0318 11:21:05.074872  2293 sgd_solver.cpp:106] Iteration 35000, lr = 0.005
I0318 11:21:07.114351  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:21:12.868957  2293 solver.cpp:228] Iteration 36000, loss = 0.0303208
I0318 11:21:12.869040  2293 solver.cpp:244]     Train net output #0: loss = 0.0276685 (* 1 = 0.0276685 loss)
I0318 11:21:12.869061  2293 sgd_solver.cpp:106] Iteration 36000, lr = 0.005
I0318 11:21:14.867756  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:21:20.612599  2293 solver.cpp:228] Iteration 37000, loss = 0.0271453
I0318 11:21:20.612680  2293 solver.cpp:244]     Train net output #0: loss = 0.0138047 (* 1 = 0.0138047 loss)
I0318 11:21:20.612701  2293 sgd_solver.cpp:106] Iteration 37000, lr = 0.005
I0318 11:21:22.612783  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:21:28.404675  2293 solver.cpp:228] Iteration 38000, loss = 0.0321935
I0318 11:21:28.404754  2293 solver.cpp:244]     Train net output #0: loss = 0.0208072 (* 1 = 0.0208072 loss)
I0318 11:21:28.404778  2293 sgd_solver.cpp:106] Iteration 38000, lr = 0.005
I0318 11:21:30.410125  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:21:36.162039  2293 solver.cpp:228] Iteration 39000, loss = 0.0249428
I0318 11:21:36.162324  2293 solver.cpp:244]     Train net output #0: loss = 0.0145786 (* 1 = 0.0145786 loss)
I0318 11:21:36.162333  2293 sgd_solver.cpp:106] Iteration 39000, lr = 0.005
I0318 11:21:38.159250  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:21:43.910400  2293 solver.cpp:337] Iteration 40000, Testing net (#0)
I0318 11:21:43.910423  2293 net.cpp:709] Ignoring source layer data_drop
I0318 11:21:43.910426  2293 net.cpp:709] Ignoring source layer data_vision
I0318 11:21:43.910432  2293 net.cpp:709] Ignoring source layer loss
I0318 11:21:44.142619  2293 solver.cpp:404]     Test net output #0: accuracy = 0.9918
I0318 11:21:44.147845  2293 solver.cpp:228] Iteration 40000, loss = 0.0264738
I0318 11:21:44.147902  2293 solver.cpp:244]     Train net output #0: loss = 0.00997595 (* 1 = 0.00997595 loss)
I0318 11:21:44.147927  2293 sgd_solver.cpp:106] Iteration 40000, lr = 0.0025
I0318 11:21:45.491529  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:21:51.900087  2293 solver.cpp:228] Iteration 41000, loss = 0.0267329
I0318 11:21:51.900115  2293 solver.cpp:244]     Train net output #0: loss = 0.0228876 (* 1 = 0.0228876 loss)
I0318 11:21:51.900120  2293 sgd_solver.cpp:106] Iteration 41000, lr = 0.0025
I0318 11:21:53.251559  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:21:59.705507  2293 solver.cpp:228] Iteration 42000, loss = 0.0219021
I0318 11:21:59.705587  2293 solver.cpp:244]     Train net output #0: loss = 0.0119271 (* 1 = 0.0119271 loss)
I0318 11:21:59.705610  2293 sgd_solver.cpp:106] Iteration 42000, lr = 0.0025
I0318 11:22:01.062155  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:22:07.472159  2293 solver.cpp:228] Iteration 43000, loss = 0.0242377
I0318 11:22:07.472240  2293 solver.cpp:244]     Train net output #0: loss = 0.0205725 (* 1 = 0.0205725 loss)
I0318 11:22:07.472261  2293 sgd_solver.cpp:106] Iteration 43000, lr = 0.0025
I0318 11:22:08.828739  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:22:15.233031  2293 solver.cpp:228] Iteration 44000, loss = 0.0206757
I0318 11:22:15.233111  2293 solver.cpp:244]     Train net output #0: loss = 0.027021 (* 1 = 0.027021 loss)
I0318 11:22:15.233132  2293 sgd_solver.cpp:106] Iteration 44000, lr = 0.0025
I0318 11:22:16.587534  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:22:22.984015  2293 solver.cpp:337] Iteration 45000, Testing net (#0)
I0318 11:22:22.984082  2293 net.cpp:709] Ignoring source layer data_drop
I0318 11:22:22.984089  2293 net.cpp:709] Ignoring source layer data_vision
I0318 11:22:22.984096  2293 net.cpp:709] Ignoring source layer loss
I0318 11:22:23.211967  2293 solver.cpp:404]     Test net output #0: accuracy = 0.992
I0318 11:22:23.215663  2293 solver.cpp:228] Iteration 45000, loss = 0.0248949
I0318 11:22:23.215718  2293 solver.cpp:244]     Train net output #0: loss = 0.0309482 (* 1 = 0.0309482 loss)
I0318 11:22:23.215747  2293 sgd_solver.cpp:106] Iteration 45000, lr = 0.0025
I0318 11:22:23.876216  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:22:31.017853  2293 solver.cpp:228] Iteration 46000, loss = 0.0255703
I0318 11:22:31.017886  2293 solver.cpp:244]     Train net output #0: loss = 0.040102 (* 1 = 0.040102 loss)
I0318 11:22:31.017894  2293 sgd_solver.cpp:106] Iteration 46000, lr = 0.0025
I0318 11:22:31.644273  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:22:38.772130  2293 solver.cpp:228] Iteration 47000, loss = 0.0248125
I0318 11:22:38.772164  2293 solver.cpp:244]     Train net output #0: loss = 0.0283726 (* 1 = 0.0283726 loss)
I0318 11:22:38.772171  2293 sgd_solver.cpp:106] Iteration 47000, lr = 0.0025
I0318 11:22:39.398895  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:22:46.527745  2293 solver.cpp:228] Iteration 48000, loss = 0.0223528
I0318 11:22:46.527827  2293 solver.cpp:244]     Train net output #0: loss = 0.0239354 (* 1 = 0.0239354 loss)
I0318 11:22:46.527848  2293 sgd_solver.cpp:106] Iteration 48000, lr = 0.0025
I0318 11:22:47.155035  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:22:54.279433  2293 solver.cpp:228] Iteration 49000, loss = 0.0218638
I0318 11:22:54.279644  2293 solver.cpp:244]     Train net output #0: loss = 0.0131459 (* 1 = 0.0131459 loss)
I0318 11:22:54.279654  2293 sgd_solver.cpp:106] Iteration 49000, lr = 0.0025
I0318 11:22:54.907881  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:23:02.037255  2293 solver.cpp:337] Iteration 50000, Testing net (#0)
I0318 11:23:02.037322  2293 net.cpp:709] Ignoring source layer data_drop
I0318 11:23:02.037328  2293 net.cpp:709] Ignoring source layer data_vision
I0318 11:23:02.037333  2293 net.cpp:709] Ignoring source layer loss
I0318 11:23:02.221326  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:23:02.254387  2293 solver.cpp:404]     Test net output #0: accuracy = 0.992
I0318 11:23:02.259177  2293 solver.cpp:228] Iteration 50000, loss = 0.0188346
I0318 11:23:02.259202  2293 solver.cpp:244]     Train net output #0: loss = 0.0181489 (* 1 = 0.0181489 loss)
I0318 11:23:02.259208  2293 sgd_solver.cpp:106] Iteration 50000, lr = 0.0025
I0318 11:23:09.952934  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:23:10.058079  2293 solver.cpp:228] Iteration 51000, loss = 0.0235058
I0318 11:23:10.058171  2293 solver.cpp:244]     Train net output #0: loss = 0.0259566 (* 1 = 0.0259566 loss)
I0318 11:23:10.058194  2293 sgd_solver.cpp:106] Iteration 51000, lr = 0.0025
I0318 11:23:17.719837  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:23:17.824699  2293 solver.cpp:228] Iteration 52000, loss = 0.023763
I0318 11:23:17.824800  2293 solver.cpp:244]     Train net output #0: loss = 0.023948 (* 1 = 0.023948 loss)
I0318 11:23:17.824836  2293 sgd_solver.cpp:106] Iteration 52000, lr = 0.0025
I0318 11:23:25.484493  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:23:25.589510  2293 solver.cpp:228] Iteration 53000, loss = 0.023353
I0318 11:23:25.590872  2293 solver.cpp:244]     Train net output #0: loss = 0.0337304 (* 1 = 0.0337304 loss)
I0318 11:23:25.590879  2293 sgd_solver.cpp:106] Iteration 53000, lr = 0.0025
I0318 11:23:33.256769  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:23:33.362195  2293 solver.cpp:228] Iteration 54000, loss = 0.0229204
I0318 11:23:33.362272  2293 solver.cpp:244]     Train net output #0: loss = 0.0202244 (* 1 = 0.0202244 loss)
I0318 11:23:33.362293  2293 sgd_solver.cpp:106] Iteration 54000, lr = 0.0025
I0318 11:23:41.024628  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:23:41.122020  2293 solver.cpp:337] Iteration 55000, Testing net (#0)
I0318 11:23:41.122038  2293 net.cpp:709] Ignoring source layer data_drop
I0318 11:23:41.122043  2293 net.cpp:709] Ignoring source layer data_vision
I0318 11:23:41.122048  2293 net.cpp:709] Ignoring source layer loss
I0318 11:23:41.366497  2293 solver.cpp:404]     Test net output #0: accuracy = 0.9915
I0318 11:23:41.373639  2293 solver.cpp:228] Iteration 55000, loss = 0.0270377
I0318 11:23:41.373695  2293 solver.cpp:244]     Train net output #0: loss = 0.0374675 (* 1 = 0.0374675 loss)
I0318 11:23:41.373723  2293 sgd_solver.cpp:106] Iteration 55000, lr = 0.0025
I0318 11:23:48.342440  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:23:49.162629  2293 solver.cpp:228] Iteration 56000, loss = 0.020236
I0318 11:23:49.163985  2293 solver.cpp:244]     Train net output #0: loss = 0.0306829 (* 1 = 0.0306829 loss)
I0318 11:23:49.163995  2293 sgd_solver.cpp:106] Iteration 56000, lr = 0.0025
I0318 11:23:56.094287  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:23:56.919549  2293 solver.cpp:228] Iteration 57000, loss = 0.0273342
I0318 11:23:56.919577  2293 solver.cpp:244]     Train net output #0: loss = 0.0174274 (* 1 = 0.0174274 loss)
I0318 11:23:56.919582  2293 sgd_solver.cpp:106] Iteration 57000, lr = 0.0025
I0318 11:24:03.847791  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:24:04.672605  2293 solver.cpp:228] Iteration 58000, loss = 0.0239269
I0318 11:24:04.672812  2293 solver.cpp:244]     Train net output #0: loss = 0.0178311 (* 1 = 0.0178311 loss)
I0318 11:24:04.672821  2293 sgd_solver.cpp:106] Iteration 58000, lr = 0.0025
I0318 11:24:11.611349  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:24:12.435411  2293 solver.cpp:228] Iteration 59000, loss = 0.0225602
I0318 11:24:12.435619  2293 solver.cpp:244]     Train net output #0: loss = 0.0163419 (* 1 = 0.0163419 loss)
I0318 11:24:12.435627  2293 sgd_solver.cpp:106] Iteration 59000, lr = 0.0025
I0318 11:24:19.382341  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:24:20.198541  2293 solver.cpp:337] Iteration 60000, Testing net (#0)
I0318 11:24:20.198603  2293 net.cpp:709] Ignoring source layer data_drop
I0318 11:24:20.198609  2293 net.cpp:709] Ignoring source layer data_vision
I0318 11:24:20.198616  2293 net.cpp:709] Ignoring source layer loss
I0318 11:24:20.415959  2293 solver.cpp:404]     Test net output #0: accuracy = 0.9922
I0318 11:24:20.419673  2293 solver.cpp:228] Iteration 60000, loss = 0.0222327
I0318 11:24:20.419695  2293 solver.cpp:244]     Train net output #0: loss = 0.0191444 (* 1 = 0.0191444 loss)
I0318 11:24:20.419703  2293 sgd_solver.cpp:106] Iteration 60000, lr = 0.00125
I0318 11:24:26.637230  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:24:28.186540  2293 solver.cpp:228] Iteration 61000, loss = 0.0223018
I0318 11:24:28.186626  2293 solver.cpp:244]     Train net output #0: loss = 0.0493041 (* 1 = 0.0493041 loss)
I0318 11:24:28.186647  2293 sgd_solver.cpp:106] Iteration 61000, lr = 0.00125
I0318 11:24:34.401680  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:24:35.950781  2293 solver.cpp:228] Iteration 62000, loss = 0.0228364
I0318 11:24:35.950901  2293 solver.cpp:244]     Train net output #0: loss = 0.0315225 (* 1 = 0.0315225 loss)
I0318 11:24:35.951028  2293 sgd_solver.cpp:106] Iteration 62000, lr = 0.00125
I0318 11:24:42.159984  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:24:43.713147  2293 solver.cpp:228] Iteration 63000, loss = 0.0222825
I0318 11:24:43.713227  2293 solver.cpp:244]     Train net output #0: loss = 0.0279787 (* 1 = 0.0279787 loss)
I0318 11:24:43.713249  2293 sgd_solver.cpp:106] Iteration 63000, lr = 0.00125
I0318 11:24:49.925043  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:24:51.475303  2293 solver.cpp:228] Iteration 64000, loss = 0.0208978
I0318 11:24:51.475383  2293 solver.cpp:244]     Train net output #0: loss = 0.0220178 (* 1 = 0.0220178 loss)
I0318 11:24:51.475404  2293 sgd_solver.cpp:106] Iteration 64000, lr = 0.00125
I0318 11:24:57.679332  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:24:59.223672  2293 solver.cpp:337] Iteration 65000, Testing net (#0)
I0318 11:24:59.223736  2293 net.cpp:709] Ignoring source layer data_drop
I0318 11:24:59.223742  2293 net.cpp:709] Ignoring source layer data_vision
I0318 11:24:59.223747  2293 net.cpp:709] Ignoring source layer loss
I0318 11:24:59.476163  2293 solver.cpp:404]     Test net output #0: accuracy = 0.9924
I0318 11:24:59.480533  2293 solver.cpp:228] Iteration 65000, loss = 0.0252623
I0318 11:24:59.480552  2293 solver.cpp:244]     Train net output #0: loss = 0.0277777 (* 1 = 0.0277777 loss)
I0318 11:24:59.480558  2293 sgd_solver.cpp:106] Iteration 65000, lr = 0.00125
I0318 11:25:04.968062  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:25:07.242836  2293 solver.cpp:228] Iteration 66000, loss = 0.0223349
I0318 11:25:07.242916  2293 solver.cpp:244]     Train net output #0: loss = 0.0219395 (* 1 = 0.0219395 loss)
I0318 11:25:07.242938  2293 sgd_solver.cpp:106] Iteration 66000, lr = 0.00125
I0318 11:25:12.730495  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:25:15.011878  2293 solver.cpp:228] Iteration 67000, loss = 0.0255736
I0318 11:25:15.011960  2293 solver.cpp:244]     Train net output #0: loss = 0.0160333 (* 1 = 0.0160333 loss)
I0318 11:25:15.011981  2293 sgd_solver.cpp:106] Iteration 67000, lr = 0.00125
I0318 11:25:20.497290  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:25:22.773385  2293 solver.cpp:228] Iteration 68000, loss = 0.0215673
I0318 11:25:22.773463  2293 solver.cpp:244]     Train net output #0: loss = 0.0166732 (* 1 = 0.0166732 loss)
I0318 11:25:22.773485  2293 sgd_solver.cpp:106] Iteration 68000, lr = 0.00125
I0318 11:25:28.268733  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:25:30.547122  2293 solver.cpp:228] Iteration 69000, loss = 0.0201854
I0318 11:25:30.547238  2293 solver.cpp:244]     Train net output #0: loss = 0.0216273 (* 1 = 0.0216273 loss)
I0318 11:25:30.547273  2293 sgd_solver.cpp:106] Iteration 69000, lr = 0.00125
I0318 11:25:36.028434  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:25:38.296542  2293 solver.cpp:337] Iteration 70000, Testing net (#0)
I0318 11:25:38.296711  2293 net.cpp:709] Ignoring source layer data_drop
I0318 11:25:38.296717  2293 net.cpp:709] Ignoring source layer data_vision
I0318 11:25:38.296721  2293 net.cpp:709] Ignoring source layer loss
I0318 11:25:38.528290  2293 solver.cpp:404]     Test net output #0: accuracy = 0.9917
I0318 11:25:38.532021  2293 solver.cpp:228] Iteration 70000, loss = 0.0212124
I0318 11:25:38.532074  2293 solver.cpp:244]     Train net output #0: loss = 0.00811656 (* 1 = 0.00811656 loss)
I0318 11:25:38.532124  2293 sgd_solver.cpp:106] Iteration 70000, lr = 0.00125
I0318 11:25:43.312355  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:25:46.284565  2293 solver.cpp:228] Iteration 71000, loss = 0.0217646
I0318 11:25:46.284782  2293 solver.cpp:244]     Train net output #0: loss = 0.0276843 (* 1 = 0.0276843 loss)
I0318 11:25:46.284791  2293 sgd_solver.cpp:106] Iteration 71000, lr = 0.00125
I0318 11:25:51.071743  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:25:54.043786  2293 solver.cpp:228] Iteration 72000, loss = 0.021417
I0318 11:25:54.043995  2293 solver.cpp:244]     Train net output #0: loss = 0.0158931 (* 1 = 0.0158931 loss)
I0318 11:25:54.044004  2293 sgd_solver.cpp:106] Iteration 72000, lr = 0.00125
I0318 11:25:58.832370  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:26:01.807879  2293 solver.cpp:228] Iteration 73000, loss = 0.0238537
I0318 11:26:01.807960  2293 solver.cpp:244]     Train net output #0: loss = 0.0123601 (* 1 = 0.0123601 loss)
I0318 11:26:01.807983  2293 sgd_solver.cpp:106] Iteration 73000, lr = 0.00125
I0318 11:26:06.574757  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:26:09.546711  2293 solver.cpp:228] Iteration 74000, loss = 0.0231283
I0318 11:26:09.546792  2293 solver.cpp:244]     Train net output #0: loss = 0.0156863 (* 1 = 0.0156863 loss)
I0318 11:26:09.546815  2293 sgd_solver.cpp:106] Iteration 74000, lr = 0.00125
I0318 11:26:14.341053  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:26:17.310086  2293 solver.cpp:337] Iteration 75000, Testing net (#0)
I0318 11:26:17.310149  2293 net.cpp:709] Ignoring source layer data_drop
I0318 11:26:17.310156  2293 net.cpp:709] Ignoring source layer data_vision
I0318 11:26:17.310163  2293 net.cpp:709] Ignoring source layer loss
I0318 11:26:17.526805  2293 solver.cpp:404]     Test net output #0: accuracy = 0.9925
I0318 11:26:17.532035  2293 solver.cpp:228] Iteration 75000, loss = 0.0212469
I0318 11:26:17.532078  2293 solver.cpp:244]     Train net output #0: loss = 0.0103591 (* 1 = 0.0103591 loss)
I0318 11:26:17.532093  2293 sgd_solver.cpp:106] Iteration 75000, lr = 0.00125
I0318 11:26:21.605567  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:26:25.289587  2293 solver.cpp:228] Iteration 76000, loss = 0.0218446
I0318 11:26:25.289798  2293 solver.cpp:244]     Train net output #0: loss = 0.0236961 (* 1 = 0.0236961 loss)
I0318 11:26:25.289808  2293 sgd_solver.cpp:106] Iteration 76000, lr = 0.00125
I0318 11:26:29.368219  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:26:33.049952  2293 solver.cpp:228] Iteration 77000, loss = 0.0210572
I0318 11:26:33.050070  2293 solver.cpp:244]     Train net output #0: loss = 0.0107433 (* 1 = 0.0107433 loss)
I0318 11:26:33.050104  2293 sgd_solver.cpp:106] Iteration 77000, lr = 0.00125
I0318 11:26:37.130069  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:26:40.811445  2293 solver.cpp:228] Iteration 78000, loss = 0.0231786
I0318 11:26:40.811524  2293 solver.cpp:244]     Train net output #0: loss = 0.0168042 (* 1 = 0.0168042 loss)
I0318 11:26:40.811545  2293 sgd_solver.cpp:106] Iteration 78000, lr = 0.00125
I0318 11:26:44.892982  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:26:48.573632  2293 solver.cpp:228] Iteration 79000, loss = 0.0217044
I0318 11:26:48.573712  2293 solver.cpp:244]     Train net output #0: loss = 0.0620029 (* 1 = 0.0620029 loss)
I0318 11:26:48.573734  2293 sgd_solver.cpp:106] Iteration 79000, lr = 0.00125
I0318 11:26:52.651764  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:26:56.324641  2293 solver.cpp:337] Iteration 80000, Testing net (#0)
I0318 11:26:56.324703  2293 net.cpp:709] Ignoring source layer data_drop
I0318 11:26:56.324709  2293 net.cpp:709] Ignoring source layer data_vision
I0318 11:26:56.324714  2293 net.cpp:709] Ignoring source layer loss
I0318 11:26:56.577590  2293 solver.cpp:404]     Test net output #0: accuracy = 0.9926
I0318 11:26:56.582116  2293 solver.cpp:228] Iteration 80000, loss = 0.0232261
I0318 11:26:56.582177  2293 solver.cpp:244]     Train net output #0: loss = 0.0204534 (* 1 = 0.0204534 loss)
I0318 11:26:56.582209  2293 sgd_solver.cpp:106] Iteration 80000, lr = 0.000625
I0318 11:26:59.948012  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:27:04.342600  2293 solver.cpp:228] Iteration 81000, loss = 0.0205573
I0318 11:27:04.342680  2293 solver.cpp:244]     Train net output #0: loss = 0.0349545 (* 1 = 0.0349545 loss)
I0318 11:27:04.342702  2293 sgd_solver.cpp:106] Iteration 81000, lr = 0.000625
I0318 11:27:07.711061  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:27:12.102877  2293 solver.cpp:228] Iteration 82000, loss = 0.0209949
I0318 11:27:12.102967  2293 solver.cpp:244]     Train net output #0: loss = 0.0192908 (* 1 = 0.0192908 loss)
I0318 11:27:12.102991  2293 sgd_solver.cpp:106] Iteration 82000, lr = 0.000625
I0318 11:27:15.470999  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:27:19.866581  2293 solver.cpp:228] Iteration 83000, loss = 0.0223328
I0318 11:27:19.866660  2293 solver.cpp:244]     Train net output #0: loss = 0.0226921 (* 1 = 0.0226921 loss)
I0318 11:27:19.866683  2293 sgd_solver.cpp:106] Iteration 83000, lr = 0.000625
I0318 11:27:23.234380  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:27:27.632485  2293 solver.cpp:228] Iteration 84000, loss = 0.0211907
I0318 11:27:27.632561  2293 solver.cpp:244]     Train net output #0: loss = 0.0324432 (* 1 = 0.0324432 loss)
I0318 11:27:27.632583  2293 sgd_solver.cpp:106] Iteration 84000, lr = 0.000625
I0318 11:27:31.002768  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:27:35.383450  2293 solver.cpp:337] Iteration 85000, Testing net (#0)
I0318 11:27:35.383471  2293 net.cpp:709] Ignoring source layer data_drop
I0318 11:27:35.383476  2293 net.cpp:709] Ignoring source layer data_vision
I0318 11:27:35.383481  2293 net.cpp:709] Ignoring source layer loss
I0318 11:27:35.602223  2293 solver.cpp:404]     Test net output #0: accuracy = 0.9924
I0318 11:27:35.608556  2293 solver.cpp:228] Iteration 85000, loss = 0.0187055
I0318 11:27:35.608582  2293 solver.cpp:244]     Train net output #0: loss = 0.0146874 (* 1 = 0.0146874 loss)
I0318 11:27:35.608590  2293 sgd_solver.cpp:106] Iteration 85000, lr = 0.000625
I0318 11:27:38.292440  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:27:43.416136  2293 solver.cpp:228] Iteration 86000, loss = 0.0205455
I0318 11:27:43.416349  2293 solver.cpp:244]     Train net output #0: loss = 0.0251135 (* 1 = 0.0251135 loss)
I0318 11:27:43.416357  2293 sgd_solver.cpp:106] Iteration 86000, lr = 0.000625
I0318 11:27:46.060756  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:27:51.186391  2293 solver.cpp:228] Iteration 87000, loss = 0.0230286
I0318 11:27:51.186472  2293 solver.cpp:244]     Train net output #0: loss = 0.0264763 (* 1 = 0.0264763 loss)
I0318 11:27:51.186494  2293 sgd_solver.cpp:106] Iteration 87000, lr = 0.000625
I0318 11:27:53.835602  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:27:58.958060  2293 solver.cpp:228] Iteration 88000, loss = 0.022444
I0318 11:27:58.958143  2293 solver.cpp:244]     Train net output #0: loss = 0.0384911 (* 1 = 0.0384911 loss)
I0318 11:27:58.958164  2293 sgd_solver.cpp:106] Iteration 88000, lr = 0.000625
I0318 11:28:01.606374  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:28:06.725991  2293 solver.cpp:228] Iteration 89000, loss = 0.0207665
I0318 11:28:06.726073  2293 solver.cpp:244]     Train net output #0: loss = 0.0118507 (* 1 = 0.0118507 loss)
I0318 11:28:06.726094  2293 sgd_solver.cpp:106] Iteration 89000, lr = 0.000625
I0318 11:28:09.363217  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:28:14.471108  2293 solver.cpp:337] Iteration 90000, Testing net (#0)
I0318 11:28:14.471128  2293 net.cpp:709] Ignoring source layer data_drop
I0318 11:28:14.471132  2293 net.cpp:709] Ignoring source layer data_vision
I0318 11:28:14.471138  2293 net.cpp:709] Ignoring source layer loss
I0318 11:28:14.688562  2293 solver.cpp:404]     Test net output #0: accuracy = 0.9922
I0318 11:28:14.693466  2293 solver.cpp:228] Iteration 90000, loss = 0.0184132
I0318 11:28:14.693483  2293 solver.cpp:244]     Train net output #0: loss = 0.016479 (* 1 = 0.016479 loss)
I0318 11:28:14.693490  2293 sgd_solver.cpp:106] Iteration 90000, lr = 0.000625
I0318 11:28:16.651388  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:28:22.479857  2293 solver.cpp:228] Iteration 91000, loss = 0.0221305
I0318 11:28:22.479938  2293 solver.cpp:244]     Train net output #0: loss = 0.0181537 (* 1 = 0.0181537 loss)
I0318 11:28:22.479962  2293 sgd_solver.cpp:106] Iteration 91000, lr = 0.000625
I0318 11:28:24.401419  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:28:30.240413  2293 solver.cpp:228] Iteration 92000, loss = 0.018978
I0318 11:28:30.240494  2293 solver.cpp:244]     Train net output #0: loss = 0.0252802 (* 1 = 0.0252802 loss)
I0318 11:28:30.240519  2293 sgd_solver.cpp:106] Iteration 92000, lr = 0.000625
I0318 11:28:32.165895  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:28:38.006335  2293 solver.cpp:228] Iteration 93000, loss = 0.0195544
I0318 11:28:38.006418  2293 solver.cpp:244]     Train net output #0: loss = 0.013972 (* 1 = 0.013972 loss)
I0318 11:28:38.006443  2293 sgd_solver.cpp:106] Iteration 93000, lr = 0.000625
I0318 11:28:39.930044  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:28:45.771206  2293 solver.cpp:228] Iteration 94000, loss = 0.0172631
I0318 11:28:45.771286  2293 solver.cpp:244]     Train net output #0: loss = 0.025345 (* 1 = 0.025345 loss)
I0318 11:28:45.771312  2293 sgd_solver.cpp:106] Iteration 94000, lr = 0.000625
I0318 11:28:47.692418  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:28:53.517742  2293 solver.cpp:337] Iteration 95000, Testing net (#0)
I0318 11:28:53.517808  2293 net.cpp:709] Ignoring source layer data_drop
I0318 11:28:53.517817  2293 net.cpp:709] Ignoring source layer data_vision
I0318 11:28:53.517822  2293 net.cpp:709] Ignoring source layer loss
I0318 11:28:53.770978  2293 solver.cpp:404]     Test net output #0: accuracy = 0.9924
I0318 11:28:53.776676  2293 solver.cpp:228] Iteration 95000, loss = 0.0203231
I0318 11:28:53.776720  2293 solver.cpp:244]     Train net output #0: loss = 0.0142679 (* 1 = 0.0142679 loss)
I0318 11:28:53.776734  2293 sgd_solver.cpp:106] Iteration 95000, lr = 0.000625
I0318 11:28:54.984524  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:29:01.546005  2293 solver.cpp:228] Iteration 96000, loss = 0.0210146
I0318 11:29:01.546047  2293 solver.cpp:244]     Train net output #0: loss = 0.0142757 (* 1 = 0.0142757 loss)
I0318 11:29:01.546054  2293 sgd_solver.cpp:106] Iteration 96000, lr = 0.000625
I0318 11:29:02.745981  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:29:09.299433  2293 solver.cpp:228] Iteration 97000, loss = 0.0183835
I0318 11:29:09.299516  2293 solver.cpp:244]     Train net output #0: loss = 0.00926929 (* 1 = 0.00926929 loss)
I0318 11:29:09.299538  2293 sgd_solver.cpp:106] Iteration 97000, lr = 0.000625
I0318 11:29:10.496659  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:29:17.049028  2293 solver.cpp:228] Iteration 98000, loss = 0.0235371
I0318 11:29:17.049055  2293 solver.cpp:244]     Train net output #0: loss = 0.010878 (* 1 = 0.010878 loss)
I0318 11:29:17.049060  2293 sgd_solver.cpp:106] Iteration 98000, lr = 0.000625
I0318 11:29:18.245985  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:29:24.798055  2293 solver.cpp:228] Iteration 99000, loss = 0.0181577
I0318 11:29:24.798267  2293 solver.cpp:244]     Train net output #0: loss = 0.00977411 (* 1 = 0.00977411 loss)
I0318 11:29:24.798277  2293 sgd_solver.cpp:106] Iteration 99000, lr = 0.000625
I0318 11:29:25.999528  2293 blocking_queue.cpp:50] Data layer prefetch queue empty
I0318 11:29:32.562167  2293 solver.cpp:454] Snapshotting to binary proto file mnist_iter_100000.caffemodel
I0318 11:29:32.565174  2293 sgd_solver.cpp:273] Snapshotting solver state to binary proto file mnist_iter_100000.solverstate
I0318 11:29:32.569958  2293 solver.cpp:317] Iteration 100000, loss = 0.0213061
I0318 11:29:32.570003  2293 solver.cpp:337] Iteration 100000, Testing net (#0)
I0318 11:29:32.570022  2293 net.cpp:709] Ignoring source layer data_drop
I0318 11:29:32.570039  2293 net.cpp:709] Ignoring source layer data_vision
I0318 11:29:32.570057  2293 net.cpp:709] Ignoring source layer loss
I0318 11:29:32.786342  2293 solver.cpp:404]     Test net output #0: accuracy = 0.9924
I0318 11:29:32.786365  2293 solver.cpp:322] Optimization Done.
I0318 11:29:32.786368  2293 caffe.cpp:254] Optimization Done.
